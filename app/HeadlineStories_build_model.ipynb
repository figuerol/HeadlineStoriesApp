{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import gensim\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Data (this data is not available in the repo)\n",
    "frame = pd.read_pickle('df_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of rows: 419814\n"
     ]
    }
   ],
   "source": [
    "#Count the number of Articles\n",
    "print('no. of rows: '+str(len(frame.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'byline.original', 'section_name', 'document_type',\n",
       "       'headline.main', 'lead_paragraph', 'snippet', 'pub_date', 'word_count',\n",
       "       'news_desk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Articles' attributes\n",
    "frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a list of lead pragraphs for each article\n",
    "paragraphs=frame['lead_paragraph']\n",
    "documents=[]\n",
    "for line in paragraphs:\n",
    "          documents.append(gensim.utils.simple_preprocess(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178728"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing number of Distict Words accross the Documents\n",
    "words=set()\n",
    "for doc in documents:\n",
    "    for word in doc:\n",
    "        if word not in words:\n",
    "            words.add(word)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sections_pairs=zip(documents,frame['section_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tagged Documents, eliminate empty documents\n",
    "tagged_documents = [TaggedDocument(doc, i) \n",
    "                    for doc, i in doc_sections_pairs if len(doc)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['as', 'some', 'of', 'us', 'know', 'from', 'personal', 'experience', 'finding', 'bedbugs', 'in', 'your', 'apartment', 'is', 'jarring', 'while', 'they', 'don', 'carry', 'diseases', 'to', 'humans', 'that', 'we', 'know', 'of', 'their', 'bites', 'are', 'itchy', 'and', 'can', 'get', 'infected'], tags='Real Estate')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample of tagged paragraph\n",
    "tagged_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Distributed Bag of Words\n",
    "#We saved the weights of this model into models/dbow_paragraph.model\n",
    "dbow = Doc2Vec(tagged_documents, vector_size=150, window=5, dm=0, min_count=2, workers=10, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(tagged_docs):\n",
    "    targets, vectors = zip(*[(doc.tags, \n",
    "                                 dbow.infer_vector(doc.words,epochs=25))\n",
    "                                for doc in tagged_docs])\n",
    "    return  vectors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data and labels\n",
    "X,y=get_vectors(tagged_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of raw data\n",
    "del documents\n",
    "del frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and test data\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,\n",
    "                               test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After performing a GridSearch\n",
    "#we concluded that\n",
    "#the higher the C parameter (weaker regularization)\n",
    "#produces better accuracy.\n",
    "#This model was saved into models/Logistic_topic_clasifier_from_paragraph.sav\n",
    "log = LogisticRegression(C=1e5)\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6775403646879268\n",
      "F1 score: 0.6631370680647448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = log.predict(X_test)\n",
    "print('Accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the predictions in terms of probability\n",
    "y_pred_proba = log.predict_proba(X_test)\n",
    "best_n = np.argsort(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of classes on sections\n",
    "len(best_n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arts', 'Automobiles', 'Blogs', 'Books', 'Booming', 'Briefing',\n",
       "       'Business Day', 'Climate', 'Corrections', 'Crosswords & Games',\n",
       "       'Education', 'Fashion & Style', 'Food',\n",
       "       'Great Homes & Destinations', 'Health', 'Home & Garden',\n",
       "       'Job Market', 'Lens', 'Magazine', 'Movies', 'Multimedia/Photos',\n",
       "       'NYT Now', 'New York', 'Opinion', 'Podcasts', 'Public Editor',\n",
       "       'Reader Center', 'Real Estate', 'Science', 'Smarter Living',\n",
       "       'Sports', 'Style', 'Sunday Review', 'T Magazine', 'Technology',\n",
       "       'The Learning Network', 'The Upshot', 'Theater', 'Times Insider',\n",
       "       'Todayâ€™s Paper', 'Travel', 'U.S.', 'Universal', 'Watching',\n",
       "       'Week in Review', 'Well', 'World', 'Your Money'], dtype='<U26')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Possible sections\n",
    "log.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number-Section dictionary\n",
    "classes_dic=zip(range(48),log.classes_)\n",
    "classDecoder=dict(classes_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the 3 most likely classes by probability\n",
    "y_pred_prob = log.predict_proba(X_test)\n",
    "best_n = np.argsort(y_pred_prob, axis=1)\n",
    "best_n_classes=[[classDecoder[s] for s in b[-3:] ] for b in best_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.860759900393606"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of being in best 3 predictions\n",
    "length=0\n",
    "successes=0\n",
    "for y,b in zip(y_test,best_n_classes):\n",
    "        length+=1\n",
    "        if y in b:\n",
    "            successes+=1\n",
    "successes/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
